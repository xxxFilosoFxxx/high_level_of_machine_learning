{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "import gzip\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise(iterable):\n",
    "        a, b = itertools.tee(iterable)\n",
    "        next(b, None)\n",
    "        return zip(a, b)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(filename, num_images, IMAGE_WIDTH):\n",
    "    print('Extracting', filename)\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(16)\n",
    "        buf = bytestream.read(IMAGE_WIDTH * IMAGE_WIDTH * num_images)\n",
    "        data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "        data = data.reshape(num_images, IMAGE_WIDTH*IMAGE_WIDTH)\n",
    "        return data\n",
    "    \n",
    "    \n",
    "def extract_labels(filename, num_images):\n",
    "    print('Extracting', filename)\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(8)\n",
    "        buf = bytestream.read(1 * num_images)\n",
    "        labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting train-images-idx3-ubyte.gz\n",
      "Extracting train-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "m = 10000\n",
    "X = extract_data('train-images-idx3-ubyte.gz', m, 28)\n",
    "Y = extract_labels('train-labels-idx1-ubyte.gz', m).reshape(m,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.cm as cm\n",
    "plt.imshow(X[6].reshape((28, 28)), cmap=cm.Greys_r)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# нормализация данных\n",
    "X -= int(np.mean(X))\n",
    "X /= int(np.std(X))\n",
    "X = X.reshape(len(X), 28, 28)    \n",
    "    \n",
    "\n",
    "X_train = []\n",
    "for i in range(len(X)):\n",
    "    x_even = X[i]\n",
    "    x_rand_1 = random.choice(X)\n",
    "    x_rand_2 = random.choice(X)\n",
    "    x_zeros = np.zeros((28, 28)).reshape((28, 28))\n",
    "    \n",
    "    prom = np.vstack((x_zeros, x_even))\n",
    "    prom = np.vstack((prom, x_zeros))\n",
    "    prom = prom.reshape((84, 28))\n",
    "    \n",
    "    rand_1 = np.vstack((x_zeros, x_rand_1))\n",
    "    rand_1 = np.vstack((rand_1, x_zeros))\n",
    "    rand_1 = rand_1.reshape((84, 28))\n",
    "    \n",
    "    rand_2 = np.vstack((x_zeros, x_rand_2))\n",
    "    rand_2 = np.vstack((rand_2, x_zeros))\n",
    "    rand_2 = rand_2.reshape((84, 28))\n",
    "    \n",
    "    x_train = np.column_stack((rand_1, prom))\n",
    "    x_train = np.column_stack((rand_2, x_train))\n",
    "    X_train.append(x_train)\n",
    "    \n",
    "# X_train = np.asarray(X_train)\n",
    "    \n",
    "# num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "# X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[6], cmap=cm.Greys_r)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "for i in Y:\n",
    "    if i[0] % 2 == [0]:\n",
    "        i[0] = 0  # число четное\n",
    "    else:\n",
    "        i[0] = 1  # число нечетное\n",
    "        \n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Utils:\n",
    "    @staticmethod\n",
    "    def sigmoid(X):\n",
    "        return 1 / (1 + np.exp(-X))\n",
    "\n",
    "            \n",
    "    @staticmethod\n",
    "    def deriv_sigmoid(X):\n",
    "        fx = Utils.sigmoid(X)\n",
    "        return fx * (1 - fx)\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def mse_loss(Y, theta):\n",
    "        return ((Y - theta) ** 2).mean()\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def softmax(X):\n",
    "        out = np.exp(X)\n",
    "        return out/np.sum(out)\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def cross_entropy_loss(Y, theta):\n",
    "        return -np.sum(Y * np.log(theta))\n",
    "    \n",
    "    @staticmethod\n",
    "    def gradient(theta, X, y):\n",
    "        m = X.shape[0]\n",
    "        gradient = (1 / m) * np.dot(X.T, (sigmoid(np.dot(X, theta)) - y))\n",
    "        return gradient \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network():\n",
    "    def __init__(self):\n",
    "        self.iterations = 5  # количество итераций для градиентного спуска\n",
    "        self.alpha = 0.1  # скорость обучения\n",
    "        self.lamda = 0.5  # параметр для регуляризации\n",
    "        self.n = 6  # слоев в нейросети\n",
    "        self.m = [84, 42, 20, 10, 5, 1]  # массив числа нейронов для каждого слоя\n",
    "        \n",
    "    \n",
    "    \n",
    "    def backpropagation(self, deriv_grad_func, y, x, weights, theta, R):\n",
    "        d_ypred = -2 * (y - theta[-1][0])\n",
    "        sum_h = 0\n",
    "        sum_old_h = 0\n",
    "        old_w = list()\n",
    "        for i in range(len(theta) - 1, 0, -1):\n",
    "            if i == len(theta) - 1:\n",
    "                old_w = weights[i]\n",
    "                for k in range(len(theta[i])):\n",
    "                    for z in range(len(weights[i][k])):\n",
    "                        sum_h += weights[i][k][z] * theta[i - 1][z]\n",
    "                    sum_h += R[i][k]\n",
    "                    for z in range(len(weights[i][k])):\n",
    "                        weights[i][k][z] -= self.alpha * d_ypred * theta[i - 1][z] * deriv_grad_func(sum_h)\n",
    "                    R[i][k] -= self.alpha * d_ypred * deriv_grad_func(sum_h)\n",
    "                    sum_h = 0\n",
    "            else:\n",
    "                present_w = weights[i]\n",
    "                for k in range(len(theta[i])):\n",
    "                    new_w = np.sum(old_w[k])\n",
    "                    for z in range(len(old_w[k])):\n",
    "                        sum_old_h += old_w[k][z] * theta[i][z]\n",
    "                    for z in range(len(weights[i][k])):\n",
    "                        sum_h += weights[i][k][z] * theta[i - 1][z]\n",
    "                    sum_h += R[i][k]\n",
    "                    for z in range(len(weights[i][k])):\n",
    "                        weights[i][k][z] -= self.alpha * d_ypred * new_w * deriv_grad_func(sum_old_h) * theta[i - 1][z] * deriv_grad_func(sum_h)\n",
    "                    R[i][k] -= self.alpha * d_ypred * new_w * deriv_grad_func(sum_old_h) * deriv_grad_func(sum_h)\n",
    "                    sum_old_h = 0\n",
    "                    sum_h = 0\n",
    "                old_w = present_w\n",
    "        for k in range(len(theta[0])):\n",
    "            new_w = np.sum(old_w[k])\n",
    "            for z in range(len(old_w[k])):\n",
    "                sum_old_h += old_w[k][z] * theta[0][z]\n",
    "            for z in range(len(weights[0][k])):\n",
    "                sum_h += weights[0][k][z] * x[k][z]\n",
    "            sum_h += R[0][k]\n",
    "            for z in range(len(weights[0][k])):\n",
    "                weights[0][k][z] -= self.alpha * d_ypred * new_w * deriv_grad_func(sum_old_h) * x[k][z] * deriv_grad_func(sum_h)\n",
    "            R[0][k] -= self.alpha * d_ypred * new_w * deriv_grad_func(sum_old_h) * deriv_grad_func(sum_h)\n",
    "            sum_old_h = 0\n",
    "            sum_h = 0\n",
    "        \n",
    "        \n",
    "    def forward(self, grad_func, x, weights, theta, R):\n",
    "        sum_h = 0\n",
    "        for k in range(len(theta[0])):\n",
    "            for z in range(len(weights[0][k])):\n",
    "                sum_h += weights[0][k][z] * x[k][z]\n",
    "            sum_h += R[0][k]\n",
    "            theta[0][k] = grad_func(sum_h)\n",
    "            sum_h = 0\n",
    "        for i in range(1, len(theta)):\n",
    "            for k in range(len(theta[i])):\n",
    "                for z in range(len(weights[i][k])):\n",
    "                    sum_h += weights[i][k][z] * theta[i - 1][z]\n",
    "                sum_h += R[i][k]\n",
    "                theta[i][k] = grad_func(sum_h)\n",
    "                sum_h = 0\n",
    "        return theta[-1]\n",
    "        \n",
    "        \n",
    "    def reg_theta(self, theta, k):\n",
    "        return (self.lamda / len(theta)) * theta[k]\n",
    "\n",
    "    \n",
    "    def gradient_descent(self, data, y_true, deriv_grad_func=Utils.deriv_sigmoid,\n",
    "                         grad_func=Utils.sigmoid, loss_func=Utils.cross_entropy_loss):\n",
    "        theta = [0] * self.n\n",
    "        weights = [0] * self.n\n",
    "        R = [0] * self.n\n",
    "        y_pred = np.array([])\n",
    "        old_y_pred = np.array([])\n",
    "        j = 0\n",
    "        for i in self.m:\n",
    "            theta[j] = np.random.randn(i, 1)\n",
    "            R[j] = np.full(i, 0.).reshape(-1, 1)\n",
    "            j += 1\n",
    "            \n",
    "        j = 1\n",
    "        weights[0] = np.random.uniform(-0.5, 0.5, size=(84, self.m[0]))  # первый параметр равен размерности X\n",
    "        for z1, z2 in pairwise(self.m):\n",
    "            weights[j] = np.random.uniform(-0.5, 0.5, size=(z1, z2))\n",
    "            j += 1\n",
    "        \n",
    "        for i in range(len(theta)):\n",
    "            for k in range(len(theta[i])):  # регуляризация каждой theta\n",
    "                new_R = self.reg_theta(theta[i], k)\n",
    "                R[i][k] = new_R\n",
    "        for iteration in tqdm(range(self.iterations)):  # обновление параметров\n",
    "            for x, y in zip(data, y_true):\n",
    "                new_y_pred = self.forward(grad_func, x, weights, theta, R)\n",
    "                self.backpropagation(deriv_grad_func, y, x, weights, theta, R)\n",
    "                y_pred = np.append(y_pred, new_y_pred[0])\n",
    "                y_pred = y_pred.reshape(len(y_pred), 1)\n",
    "            if iteration % 1 == 0:\n",
    "                loss = loss_func(y_true[:len(y_pred)], y_pred)\n",
    "                print(\"Epoch %d loss: %.3f\" % (iteration + 1, loss))\n",
    "                y_pred = old_y_pred\n",
    "        \n",
    "        return theta, weights, R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [37:02<2:28:08, 2222.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 2760.013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 2/5 [1:13:24<1:50:30, 2210.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 loss: 1962.907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 3/5 [1:42:34<1:09:04, 2072.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 loss: 1832.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 4/5 [2:11:58<32:59, 1979.84s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 loss: 2019.611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [2:41:30<00:00, 1938.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 loss: 2093.701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "network = Network()\n",
    "theta, weights, R = network.gradient_descent(X_train, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting t10k-images-idx3-ubyte.gz\n",
      "Extracting t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "_max = 10000\n",
    "X_t = extract_data('t10k-images-idx3-ubyte.gz', _max, 28)\n",
    "Y_test = extract_labels('t10k-labels-idx1-ubyte.gz', _max).reshape(_max,1)\n",
    "\n",
    "X_t -= int(np.mean(X_t))\n",
    "X_t /= int(np.std(X_t))\n",
    "X_t = X_t.reshape(len(X_t), 28, 28)\n",
    "\n",
    "X_test = []\n",
    "for i in range(len(X_t)):\n",
    "    x_even = X_t[i]\n",
    "    x_rand_1 = random.choice(X_t)\n",
    "    x_rand_2 = random.choice(X_t)\n",
    "    x_zeros = np.zeros((28, 28)).reshape((28, 28))\n",
    "    \n",
    "    prom = np.vstack((x_zeros, x_even))\n",
    "    prom = np.vstack((prom, x_zeros))\n",
    "    prom = prom.reshape((84, 28))\n",
    "    \n",
    "    rand_1 = np.vstack((x_zeros, x_rand_1))\n",
    "    rand_1 = np.vstack((rand_1, x_zeros))\n",
    "    rand_1 = rand_1.reshape((84, 28))\n",
    "    \n",
    "    rand_2 = np.vstack((x_zeros, x_rand_2))\n",
    "    rand_2 = np.vstack((rand_2, x_zeros))\n",
    "    rand_2 = rand_2.reshape((84, 28))\n",
    "    \n",
    "    x_test = np.column_stack((rand_1, prom))\n",
    "    x_test = np.column_stack((rand_2, x_test))\n",
    "    X_test.append(x_test)\n",
    "\n",
    "for i in Y_test:\n",
    "    if i[0] % 2 == [0]:\n",
    "        i[0] = 0  # число четное\n",
    "    else:\n",
    "        i[0] = 1  # число нечетное"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7280\n",
      "Overall Accuracy: 72.80\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "accuary = 0\n",
    "for i in X_test:\n",
    "    res = network.forward(Utils.sigmoid, i, weights, theta, R)\n",
    "    if Y_test[n][0] == 1 and res[0][0] > 0.1:\n",
    "        accuary += 1\n",
    "    elif Y_test[n][0] == 0 and res[0][0] < 0.1:\n",
    "        accuary += 1\n",
    "    # print(str(Y_test[n]) + '->' + str(res))\n",
    "    n += 1\n",
    "print(accuary)\n",
    "print(\"Overall Accuracy: %.2f\" % (float(accuary/len(X_test)*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
